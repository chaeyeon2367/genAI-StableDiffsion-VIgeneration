
</br>

# üåàAI Image and Video Generation Project with Stable Diffusion

</br> 

## üí° Project Overview
This repository showcases the results of an AI image and video generation project using Stable Diffusion. The project involves utilizing the Stable Diffusion WebUI for Prompt Engineering, ControlNet, Dreambooth, and LoRA Generative AI models. Dreambooth and LoRA models have been trained on a custom dataset,and the generated content is included in this repository.

</br> 

## üè∑ Table of Contents

1. [Stable Diffusion Introduction and WebUI Installation](#1-stable-diffusion-introduction-and-webui-installation)
2. [Text to Image (t2i)](#2-text-to-image)
3. [Image to Image (i2i)](#3-image-to-image)
4. [How to Write Prompts](#4-How-to-Write-Prompts)
5. [ControlNet Variants](#5-controlnet-variants)
6. [Dreambooth,LoRA Models Training](#6-Dreambooth-LoRA-Models-Training)
7. [Video Generation with Deforum](#7-video-generation-with-deforum)
8. [Animating Real-Person Videos with Move to Move](#8-animating-real-human-videos-with-move-to-move)
9. [Video Generation with Animatediff](#9-video-generation-with-animatediff)

</br> 

## 1. Stable Diffusion Introduction and WebUI Installation
</br> 

### üìå What is Stable diffusion?

Stable Diffusion is a generative AI technique that involves the controlled diffusion of information throughout a system. Diffusion models are probabilistic models that describe how data, in this case, an image, changes or diffuses over time. The stable diffusion approach aims to create high-quality and diverse images by iteratively applying controlled diffusion processes to an initial image.

In the context of AI and creative applications, stable diffusion is often used to generate visually appealing and novel artworks. By manipulating the diffusion process through prompts and input parameters, users can guide the AI in creating unique and imaginative images. The stability in diffusion refers to the controlled and coherent evolution of the image during the generation process.

The technique is versatile, allowing users to explore a wide range of creative possibilities by influencing factors such as lighting, style, environment, and more. It is particularly popular in the field of generative art, where artists and AI enthusiasts leverage stable diffusion to produce captivating and diverse visual content.

</br>   

### Install Stable Diffusion Webui on Colab and Locally


  - Stable Diffusion models(checkpoint)


## 2. Text to Image (t2i)
  - Results of Text to Image generation

    
## 3. Image to Image (i2i)
  - Results of Image to Image generation

## 4. How to Write Prompts
    
## 5. ControlNet Variants

  - Different types of ControlNet models and their applications
    
## 6. Dreambooth,LoRA Models Training

  - Dreambooth,LoRA Model Training and results 
  - Differences between Dreambooth and LoRA models

## 7. Video Generation with Deforum

  - Using Deforum for generating AI videos
    
## 8. Animating Real-human Videos with Move to Move

  - Transforming real human videos into animated sequences

## 9. Video Generation with Animatediff

  - Using Animatediff for generating dynamic and animated videos












Follow the steps below to set up the project locally:

```bash
git clone https://github.com/your-username/your-repository.git
cd your-repository
# Add instructions for any specific setup steps if necessary

